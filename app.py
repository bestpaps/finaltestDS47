# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qh_pcb8FCGGY3UBgFmzJZwzCxL_sy7aR
"""

import streamlit as st
import pandas as pd
import joblib
import nltk
import re
import os

# --- DEBUGGING: Cek isi direktori saat ini dan path NLTK ---
st.write(f"Direktori kerja saat ini (os.getcwd()): {os.getcwd()}")
st.write(f"Isi direktori kerja saat ini (os.listdir('.')): {os.listdir('.')}")

# --- BARIS YANG DIUBAH ---
# Gunakan path absolut berdasarkan direktori kerja saat ini
nltk_data_path = os.path.join(os.getcwd(), 'nltk_data')
# -------------------------

st.write(f"Path yang dihitung untuk nltk_data: {nltk_data_path}")

if os.path.exists(nltk_data_path):
    st.write(f"Folder nltk_data ditemukan di: {nltk_data_path}")
    # ... (sisa kode debugging Anda bisa tetap ada untuk sementara)
else:
    st.error(f"Folder nltk_data TIDAK DITEMUKAN di path: {nltk_data_path}")

if nltk_data_path not in nltk.data.path:
    nltk.data.path.insert(0, nltk_data_path) # Coba masukkan ke awal list
    st.write(f"Path {nltk_data_path} ditambahkan ke nltk.data.path")
else:
    st.write(f"Path {nltk_data_path} sudah ada di nltk.data.path")

st.write(f"NLTK data path setelah modifikasi: {nltk.data.path}")
# --- AKHIR DEBUGGING ---

# Sekarang baru import modul NLTK yang membutuhkan data tersebut
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
# Jika Anda menggunakan stemming di Colab, uncomment baris berikut dan pastikan PorterStemmer diimpor
# from nltk.stem import PorterStemmer

# --- Fungsi Preprocessing
def preprocess_text_streamlit(text):
    # Hapus URL
    text = re.sub(r'http\S+', '', text)
    # Hapus karakter khusus dan angka (sesuaikan jika angka penting)
    text = re.sub(r'[^a-zA-Z\s]', '', text.lower())
    # Tokenisasi
    tokens = word_tokenize(text)
    # Hapus stopwords
    stop_words = set(stopwords.words('english')) # Pastikan sama dengan yang di Colab
    tokens = [w for w in tokens if not w in stop_words]
    # Stemming (jika digunakan di Colab)
    # stemmer = PorterStemmer()
    # tokens = [stemmer.stem(word) for word in tokens]
    return " ".join(tokens)

# --- Memuat Model dan Vectorizer ---
@st.cache_resource # Menggunakan st.cache_resource untuk model dan vectorizer
def load_model_and_vectorizer():
    try:
        model = joblib.load('sentiment_model.pkl')
        vectorizer = joblib.load('tfidf_vectorizer.pkl')
        return model, vectorizer
    except FileNotFoundError:
        st.error("File model atau vectorizer tidak ditemukan. Pastikan 'sentiment_model.pkl' dan 'tfidf_vectorizer.pkl' berada di direktori yang sama dengan app.py.")
        return None, None
    except Exception as e:
        st.error(f"Terjadi kesalahan saat memuat model: {e}")
        return None, None

@st.cache_data # Menggunakan st.cache_data untuk data yang jarang berubah
def load_label_map():
    try:
        reverse_label_map = joblib.load('reverse_label_map.pkl') # Muat pemetaan label
        return reverse_label_map
    except FileNotFoundError:
        st.error("File reverse_label_map.pkl tidak ditemukan.")
        return None
    except Exception as e:
        st.error(f"Terjadi kesalahan saat memuat pemetaan label: {e}")
        return None

model, vectorizer = load_model_and_vectorizer()
reverse_label_map = load_label_map()

# --- Antarmuka Pengguna Streamlit ---
st.title("Analisis Sentimen Tweet")
st.write("Masukkan teks tweet di bawah ini untuk memprediksi jenis sentimen/cyberbullying.")

# Input teks dari pengguna
user_input = st.text_area("Ketik teks Anda di sini:", "Contoh teks tweet...")

# Tombol untuk melakukan prediksi
if st.button("Analisis Sentimen"):
    if model and vectorizer and reverse_label_map: # Pastikan semua resource berhasil dimuat
        if user_input:
            # 1. Preprocess input pengguna
            cleaned_input = preprocess_text_streamlit(user_input)

            # 2. Transformasi menggunakan TF-IDF Vectorizer yang sudah di-fit
            input_vector = vectorizer.transform([cleaned_input])

            # 3. Lakukan prediksi
            prediction = model.predict(input_vector)
            prediction_proba = model.predict_proba(input_vector)

            # Mapping kembali label numerik ke label teks
            predicted_sentiment = reverse_label_map.get(prediction[0], "Tidak Diketahui")

            st.subheader("Hasil Prediksi:")
            st.write(f"**Sentimen:** {predicted_sentiment}")

            if hasattr(model, "predict_proba"):
                st.subheader("Probabilitas Sentimen:")
                for i, class_label_index in enumerate(model.classes_):
                    class_name = reverse_label_map.get(class_label_index, f"Kelas {class_label_index}")
                    st.write(f"{class_name}: {prediction_proba[0][i]:.2f}")
        else:
            st.warning("Silakan masukkan teks untuk dianalisis.")
    else:
        st.error("Model atau resource lainnya tidak dapat dimuat. Periksa pesan error di atas.")

st.sidebar.header("Tentang Aplikasi Ini")
st.sidebar.info(
    "Aplikasi ini menggunakan model Machine Learning (Naive Bayes) "
    "untuk memprediksi sentimen dari teks yang Anda masukkan. "
    "Model dilatih pada dataset tweet (contoh)."
)

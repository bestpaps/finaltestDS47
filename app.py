# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qh_pcb8FCGGY3UBgFmzJZwzCxL_sy7aR
"""

import streamlit as st
import pandas as pd
import joblib
import nltk
import re
import os

# --- DEBUGGING: Cek isi direktori saat ini dan path NLTK ---
st.write(f"Direktori kerja saat ini: {os.getcwd()}")
st.write(f"Isi direktori kerja saat ini: {os.listdir('.')}") # Daftar file dan folder di root

# Tambahkan path ke data NLTK lokal
nltk_data_path = os.path.join(os.path.dirname(__file__), 'nltk_data')
st.write(f"Path yang dihitung untuk nltk_data: {nltk_data_path}")

if os.path.exists(nltk_data_path):
    st.write(f"Folder nltk_data ditemukan di: {nltk_data_path}")
    st.write(f"Isi folder nltk_data: {os.listdir(nltk_data_path)}")
    if os.path.exists(os.path.join(nltk_data_path, 'tokenizers')):
        st.write(f"Folder tokenizers ditemukan di dalam nltk_data.")
        st.write(f"Isi folder tokenizers: {os.listdir(os.path.join(nltk_data_path, 'tokenizers'))}")
        if os.path.exists(os.path.join(nltk_data_path, 'tokenizers', 'punkt')):
            st.write(f"Folder punkt ditemukan di dalam tokenizers.")
            st.write(f"Isi folder punkt: {os.listdir(os.path.join(nltk_data_path, 'tokenizers', 'punkt'))}")
        else:
            st.warning("Folder 'punkt' TIDAK DITEMUKAN di dalam 'nltk_data/tokenizers/'")
    else:
        st.warning("Folder 'tokenizers' TIDAK DITEMUKAN di dalam 'nltk_data'")
else:
    st.error(f"Folder nltk_data TIDAK DITEMUKAN di path: {nltk_data_path}")

if nltk_data_path not in nltk.data.path:
    nltk.data.path.append(nltk_data_path)
    st.write(f"Path {nltk_data_path} ditambahkan ke nltk.data.path")

st.write(f"NLTK data path setelah modifikasi: {nltk.data.path}")
# --- AKHIR DEBUGGING ---

# Sekarang baru import modul NLTK yang membutuhkan data tersebut
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
# Jika Anda menggunakan stemming di Colab, uncomment baris berikut dan pastikan PorterStemmer diimpor
# from nltk.stem import PorterStemmer

# --- Fungsi Preprocessing
def preprocess_text_streamlit(text):
    # Hapus URL
    text = re.sub(r'http\S+', '', text)
    # Hapus karakter khusus dan angka (sesuaikan jika angka penting)
    text = re.sub(r'[^a-zA-Z\s]', '', text.lower())
    # Tokenisasi
    tokens = word_tokenize(text)
    # Hapus stopwords
    stop_words = set(stopwords.words('english')) # Pastikan sama dengan yang di Colab
    tokens = [w for w in tokens if not w in stop_words]
    # Stemming (jika digunakan di Colab)
    # stemmer = PorterStemmer()
    # tokens = [stemmer.stem(word) for word in tokens]
    return " ".join(tokens)

# --- Memuat Model dan Vectorizer ---
@st.cache_resource # Menggunakan st.cache_resource untuk model dan vectorizer
def load_model_and_vectorizer():
    try:
        model = joblib.load('sentiment_model.pkl')
        vectorizer = joblib.load('tfidf_vectorizer.pkl')
        return model, vectorizer
    except FileNotFoundError:
        st.error("File model atau vectorizer tidak ditemukan. Pastikan 'sentiment_model.pkl' dan 'tfidf_vectorizer.pkl' berada di direktori yang sama dengan app.py.")
        return None, None
    except Exception as e:
        st.error(f"Terjadi kesalahan saat memuat model: {e}")
        return None, None

@st.cache_data # Menggunakan st.cache_data untuk data yang jarang berubah
def load_label_map():
    try:
        reverse_label_map = joblib.load('reverse_label_map.pkl') # Muat pemetaan label
        return reverse_label_map
    except FileNotFoundError:
        st.error("File reverse_label_map.pkl tidak ditemukan.")
        return None
    except Exception as e:
        st.error(f"Terjadi kesalahan saat memuat pemetaan label: {e}")
        return None

model, vectorizer = load_model_and_vectorizer()
reverse_label_map = load_label_map()

# --- Antarmuka Pengguna Streamlit ---
st.title("Analisis Sentimen Tweet")
st.write("Masukkan teks tweet di bawah ini untuk memprediksi jenis sentimen/cyberbullying.")

# Input teks dari pengguna
user_input = st.text_area("Ketik teks Anda di sini:", "Contoh teks tweet...")

# Tombol untuk melakukan prediksi
if st.button("Analisis Sentimen"):
    if model and vectorizer and reverse_label_map: # Pastikan semua resource berhasil dimuat
        if user_input:
            # 1. Preprocess input pengguna
            cleaned_input = preprocess_text_streamlit(user_input)

            # 2. Transformasi menggunakan TF-IDF Vectorizer yang sudah di-fit
            input_vector = vectorizer.transform([cleaned_input])

            # 3. Lakukan prediksi
            prediction = model.predict(input_vector)
            prediction_proba = model.predict_proba(input_vector)

            # Mapping kembali label numerik ke label teks
            predicted_sentiment = reverse_label_map.get(prediction[0], "Tidak Diketahui")

            st.subheader("Hasil Prediksi:")
            st.write(f"**Sentimen:** {predicted_sentiment}")

            if hasattr(model, "predict_proba"):
                st.subheader("Probabilitas Sentimen:")
                for i, class_label_index in enumerate(model.classes_):
                    class_name = reverse_label_map.get(class_label_index, f"Kelas {class_label_index}")
                    st.write(f"{class_name}: {prediction_proba[0][i]:.2f}")
        else:
            st.warning("Silakan masukkan teks untuk dianalisis.")
    else:
        st.error("Model atau resource lainnya tidak dapat dimuat. Periksa pesan error di atas.")

st.sidebar.header("Tentang Aplikasi Ini")
st.sidebar.info(
    "Aplikasi ini menggunakan model Machine Learning (Naive Bayes) "
    "untuk memprediksi sentimen dari teks yang Anda masukkan. "
    "Model dilatih pada dataset tweet (contoh)."
)

# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qh_pcb8FCGGY3UBgFmzJZwzCxL_sy7aR
"""

import streamlit as st
import pandas as pd
import joblib
import nltk
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

try:
    nltk.data.find('tokenizers/punkt')
except LookupError: # Menangkap LookupError yang lebih umum
    nltk.download('punkt', quiet=True)

try:
    nltk.data.find('corpora/stopwords')
except LookupError: # Menangkap LookupError yang lebih umum
    nltk.download('stopwords', quiet=True)
    
# --- Fungsi Preprocessing
def preprocess_text_streamlit(text):
    # Hapus URL
    text = re.sub(r'http\S+', '', text)
    # Hapus karakter khusus dan angka (sesuaikan jika angka penting)
    text = re.sub(r'[^a-zA-Z\s]', '', text.lower())
    # Tokenisasi
    tokens = word_tokenize(text)
    # Hapus stopwords
    stop_words = set(stopwords.words('english')) # Pastikan sama dengan yang di Colab
    tokens = [w for w in tokens if not w in stop_words]
    # Stemming (jika digunakan di Colab)
    # stemmer = PorterStemmer()
    # tokens = [stemmer.stem(word) for word in tokens]
    return " ".join(tokens)

# --- Memuat Model, Vectorizer, dan Pemetaan Label
@st.cache_data() # Gunakan st.cache_data untuk caching
def load_resources():
    try:
        model = joblib.load('sentiment_model.pkl')
        vectorizer = joblib.load('tfidf_vectorizer.pkl')
        reverse_label_map = joblib.load('reverse_label_map.pkl') # Muat pemetaan label
        return model, vectorizer, reverse_label_map
    except FileNotFoundError:
        st.error("File model, vectorizer, atau label_map tidak ditemukan. Pastikan semuanya ada di direktori yang sama.")
        return None, None, None
    except Exception as e:
        st.error(f"Terjadi kesalahan saat memuat resource: {e}")
        return None, None, None

model, vectorizer, reverse_label_map = load_resources()

# --- Antarmuka Pengguna Streamlit ---
st.title("Analisis Sentimen Tweet")
st.write("Masukkan teks tweet di bawah ini untuk memprediksi jenis sentimen/cyberbullying.")

# Input teks dari pengguna
user_input = st.text_area("Ketik teks Anda di sini:", "Contoh teks tweet...")

# Tombol untuk melakukan prediksi
if st.button("Analisis Sentimen"):
    if model and vectorizer and reverse_label_map: # Pastikan semua resource berhasil dimuat
        if user_input:
            # 1. Preprocess input pengguna
            cleaned_input = preprocess_text_streamlit(user_input)

            # 2. Transformasi menggunakan TF-IDF Vectorizer yang sudah di-fit
            input_vector = vectorizer.transform([cleaned_input])

            # 3. Lakukan prediksi
            prediction = model.predict(input_vector)
            prediction_proba = model.predict_proba(input_vector)

            # Mapping kembali label numerik ke label teks
            predicted_sentiment = reverse_label_map.get(prediction[0], "Tidak Diketahui")

            st.subheader("Hasil Prediksi:")
            st.write(f"**Sentimen:** {predicted_sentiment}")

            if hasattr(model, "predict_proba"):
                st.subheader("Probabilitas Sentimen:")
                for i, class_label_index in enumerate(model.classes_):
                    class_name = reverse_label_map.get(class_label_index, f"Kelas {class_label_index}")
                    st.write(f"{class_name}: {prediction_proba[0][i]:.2f}")
        else:
            st.warning("Silakan masukkan teks untuk dianalisis.")
    else:
        st.error("Model atau resource lainnya tidak dapat dimuat. Periksa pesan error di atas.")

st.sidebar.header("Tentang Aplikasi Ini")
st.sidebar.info(
    "Aplikasi ini menggunakan model Machine Learning (Naive Bayes) "
    "untuk memprediksi sentimen dari teks yang Anda masukkan. "
    "Model dilatih pada dataset tweet (contoh)."
)
